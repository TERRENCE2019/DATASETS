{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4Working with Python & Spark part 3 Copy",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TERRENCE2019/DATASETS/blob/master/4Working_with_Python_%26_Spark_part_3_Copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01zX56FFVhDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import Pyspark\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJP3skDJVm4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import operating system\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.2-bin-hadoop2.7\"\n",
        "#Import Spark\n",
        "import findspark\n",
        "# Use this\n",
        "findspark.init('spark-2.4.4-bin-hadoop2.7')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbyjKiQgEzzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tools we need to connect to the Spark server, load our data,\n",
        "# clean it and prepare it\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.sql.functions import isnan, when, count, col"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaxxdLkSZC_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "import pyspark.sql.functions as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH0BLLvt_s7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#I had to upload file because of its size to Google Drive and then pull into Google Colab\n",
        "#I now have to import necessary codes to access data file from my Google Drive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0lfS7DOEN6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The code to Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKoK-SvYEO3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This code confirms that the entire dataset in the link is read\n",
        "link = 'https://drive.google.com/open?id=1BXYyBAsiuytHk2-Zd3LfyVEAWpgQ5GRH'\n",
        "fluff, id = link.split('=')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lCFDmLeEpi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#verifies that extension after '=' is there\n",
        "print (id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIohRQ54EsFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Final step to upload data set from Google Colab\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('FLIGHTDELAYS.csv')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71CHYy-9ceVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a dataframe in PySpark compared to in Python where Pandas is used \n",
        "Airline = spark.read.format(\"csv\").option(\"header\", \"true\").load('FLIGHTDELAYS.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhG1J8W8eW97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Number of Rows\n",
        "Airline.count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQbh1kGjea5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Number of Columns\n",
        "len(Airline.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FwOarxmd_gm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print((Airline.count(), len(Airline.columns)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_GMoMujerP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Drop the rows containing any null or NaN values.\n",
        "Airline = Airline.na.drop()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAqdR__Weu1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Airline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbPYgym8ffR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Airline.dtypes\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRA4vT1SGy1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up constants\n",
        "%env SPARK_LOCAL_HOSTNAME=localhost\n",
        "\n",
        "APP_NAME = \"Flight Delays\"\n",
        "SPARK_URL = \"local[*]\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}